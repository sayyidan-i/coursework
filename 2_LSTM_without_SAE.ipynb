{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZleRWFi_caa"
      },
      "source": [
        "# All Python packages"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Jacob12138xieyuan/EEG-Based-Emotion-Recognition-on-DEAP"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shWBHUlOANIs",
        "outputId": "a7672258-8b7c-4877-faed-13f6bbad0ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'EEG-Based-Emotion-Recognition-on-DEAP'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
            "remote: Total 57 (delta 5), reused 47 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/EEG-Based-Emotion-Recognition-on-DEAP/eeg_entropy.py"
      ],
      "metadata": {
        "id": "THlKxJGgAmmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install eeg_entropy"
      ],
      "metadata": {
        "id": "cyxNJVKOA9i0",
        "outputId": "6b2cfc4f-d91f-47d1-e3e7-344fc2b14014",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement eeg_entropy (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for eeg_entropy\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACUA7_dk_car",
        "outputId": "46b800e0-18bf-404e-f31b-b528f7a01ad8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy) (1.21.6)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (3.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.4.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (3.0.8)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (1.21.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
            "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
            "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0.dev2021122109)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.44.0)\n",
            "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
            "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.25.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (2.8.0)\n",
            "Requirement already satisfied: mne in /usr/local/lib/python3.7/dist-packages (1.0.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.7/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from mne) (1.21.6)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from mne) (2.11.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from mne) (3.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from mne) (4.64.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mne) (21.3)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from mne) (1.4.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (2.23.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.7/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mne) (3.0.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2021.10.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->pooch>=1.5->mne) (2.10)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->mne) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->mne) (1.4.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->mne) (4.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->mne) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install numpy\n",
        "!pip3 install sklearn\n",
        "!pip3 install scipy\n",
        "!pip3 install matplotlib\n",
        "!pip3 install tensorflow\n",
        "!pip3 install keras\n",
        "!pip3 install mne"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "4yUDMmi0_cay",
        "outputId": "78715aca-a43e-4fd5-881c-59c55eda72d9"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-e88588d78c4b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0meeg_entropy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'eeg_entropy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from IPython.utils import io\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "import scipy.io\n",
        "from scipy import signal, integrate\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, LSTM, Dropout\n",
        "\n",
        "import mne\n",
        "import eeg_entropy\n",
        "import math\n",
        "\n",
        "n_second = 60\n",
        "n_segment = 2*n_second-1\n",
        "n_points = n_second*128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqRFOb3h_ca1"
      },
      "source": [
        "# Load np data and balance high and low label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfB9oZr2_ca2"
      },
      "outputs": [],
      "source": [
        "def load_np_data(dimension):\n",
        "    if dimension == 'valence':\n",
        "        all_labels, all_data = np.load('../Data/processed_DEAP/valence/' + 'all_valence_labels.npy', allow_pickle=True), np.load('../Data/processed_DEAP/valence/' + 'all_valence_data.npy', allow_pickle=True)\n",
        "        print(\"Total valence: \", all_labels.shape, all_data.shape)\n",
        "        #print(\"High and low valence: \", collections.Counter(all_labels))# 587 high valence, 472 low valence\n",
        "    elif dimension == 'arousal':\n",
        "        all_labels, all_data = np.load('../Data/processed_DEAP/arousal/' + 'all_arousal_labels.npy', allow_pickle=True), np.load('../Data/processed_DEAP/arousal/' + 'all_arousal_data.npy', allow_pickle=True)\n",
        "        print(\"Total arousal: \", all_labels.shape, all_data.shape)\n",
        "        #print(\"High and low arousal: \", collections.Counter(all_labels))# 620 high arousal, 462 low arousal\n",
        "    return all_labels, all_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rI46N21C_ca5"
      },
      "outputs": [],
      "source": [
        "# all_labels, all_data = load_np_data(dimension=\"valence\")\n",
        "all_labels, all_data = load_np_data(dimension=\"arousal\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-4Fa5rLO_ca9"
      },
      "outputs": [],
      "source": [
        "# after standardised\n",
        "print(np.amax(all_data)) # max value\n",
        "print(np.amin(all_data)) # min value\n",
        "\n",
        "# print(np.amax(all_valence_data[0])) # max value\n",
        "# print(np.amin(all_valence_data[0])) # min value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8xwSDRC_cbA"
      },
      "source": [
        "# Feature extraction method (Power)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2msDFxh_cbD"
      },
      "outputs": [],
      "source": [
        "def trial_psd_extraction_integration(data): # data shape (12, 8064)\n",
        "    info = mne.create_info(ch_names= ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32'], sfreq=128);\n",
        "    raw = mne.io.RawArray(data, info, first_samp=0, copy='auto', verbose=None);\n",
        "    psd_origin, f = mne.time_frequency.psd_welch(raw, fmin=0, fmax=60, n_fft=128, n_overlap=64, n_per_seg=128, picks='all', window='hann', average=None, verbose=None)# average='mean' or None\n",
        "    # print(psd_origin.shape, f.shape) # (12, 61, 125) (61,) 61 frequency\n",
        "    psd = np.moveaxis(psd_origin, -1, 0) # (125, 12, 61)\n",
        "    # calculate frequency band power using integration\n",
        "    band_power = [] # band power for all segments\n",
        "    for segment in psd:\n",
        "        segment_band_power = [] # band power for all channels in one segment\n",
        "        for psd_channel in segment:\n",
        "            y_int = integrate.cumtrapz(psd_channel, f, initial=0) # integrate to calculate band power\n",
        "            one_band_power = np.array([y_int[7]-y_int[4],y_int[13]-y_int[8],y_int[30]-y_int[14],y_int[51]-y_int[31]])\n",
        "            segment_band_power.append(one_band_power)\n",
        "        band_power.append(segment_band_power)\n",
        "    band_power = np.array(band_power) # (125, 12, 4)\n",
        "    band_power = np.moveaxis(band_power, -1, 1) # (125, 4, 12)\n",
        "    band_power = band_power.reshape((n_segment, 32*4)) # flatten feature (125, 48)\n",
        "    band_power = 10*band_power\n",
        "    return band_power"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIyCX8VF_cbH"
      },
      "source": [
        "# 10-fold cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWHPzo3N_cbI"
      },
      "outputs": [],
      "source": [
        "all_data, all_labels = shuffle(all_data, all_labels, random_state=0)\n",
        "n = len(all_labels) # 1059\n",
        "print(n)\n",
        "fold_n = math.floor(n/10) # 105\n",
        "print(fold_n)\n",
        "all_data, all_labels = all_data[:10*fold_n], all_labels[:10*fold_n] # (1050, 32, 8064)\n",
        "print(all_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TRXvetPI_cbL"
      },
      "outputs": [],
      "source": [
        "def process(test_fold_number):\n",
        "    # train has 9 folds, test has 1 fold\n",
        "    train_data = np.concatenate((all_data[:test_fold_number*fold_n], all_data[fold_n+test_fold_number*fold_n:]), axis=0)\n",
        "    train_labels = np.concatenate((all_labels[:test_fold_number*fold_n], all_labels[fold_n+test_fold_number*fold_n:]), axis=0)\n",
        "    test_data = all_data[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n",
        "    test_labels = all_labels[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n",
        "    print(train_data.shape,test_data.shape) # (945, 32, 8064) (105, 32, 8064)\n",
        "\n",
        "    # -------- Feature extraction from 32 original signal --------\n",
        "    train_band_power = [] # band power feature sequence for train trials\n",
        "    for data in train_data: # for every train trial\n",
        "        with io.capture_output() as captured:\n",
        "            trial_band_power = trial_psd_extraction_integration(data) # data shape (32, 8064)\n",
        "        train_band_power.append(trial_band_power)\n",
        "    train_band_power = np.array(train_band_power)\n",
        "\n",
        "    test_band_power = [] # band power feature sequence for test trials\n",
        "    for data in test_data: # for every test trial\n",
        "        with io.capture_output() as captured:\n",
        "            trial_band_power = trial_psd_extraction_integration(data) # data shape (32, 8064)\n",
        "        test_band_power.append(trial_band_power)\n",
        "    test_band_power = np.array(test_band_power)\n",
        "    print(\"All features of training data shape: \", train_band_power.shape) # shape (849, 125, 128)\n",
        "    print(\"All features of test data shape: \", test_band_power.shape) # shape (95, 125, 128)\n",
        "\n",
        "    # -------- Create new LSTM model --------\n",
        "    x=Input(shape=(n_segment,4*32)) # flatten (12,4) to 48\n",
        "    x1=LSTM(n_segment)(x)\n",
        "    x2=Dense(n_segment)(x1)\n",
        "    x3=Dense(12)(x2)\n",
        "    output=Dense(1, activation=\"sigmoid\")(x2)\n",
        "    model=Model(x, output)\n",
        "\n",
        "    # -------- Compile and train LSTM --------\n",
        "    model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
        "    history = model.fit(train_band_power, train_labels, epochs=30, batch_size=8, validation_data=(test_band_power, test_labels))\n",
        "    print(\"Hightest accuracy: \" + str(max(history.history['val_accuracy'])))\n",
        "    model.save(\"../Results/LSTM_model/LSTM_model_test_fold_\" + str(test_fold_number))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFAqvud__cbN"
      },
      "outputs": [],
      "source": [
        "for i in range(10):\n",
        "    print(\"********** Test Fold \" + str(i) + \" ************\")\n",
        "    process(i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "96Veorgq_cbO"
      },
      "source": [
        "# Test each section in process() function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSJ9doMc_cbQ"
      },
      "outputs": [],
      "source": [
        "test_fold_number = 0\n",
        "# train has 9 folds, test has 1 fold\n",
        "train_data = np.concatenate((all_data[:test_fold_number*fold_n], all_data[fold_n+test_fold_number*fold_n:]), axis=0)\n",
        "train_labels = np.concatenate((all_labels[:test_fold_number*fold_n], all_labels[fold_n+test_fold_number*fold_n:]), axis=0)\n",
        "test_data = all_data[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n",
        "test_labels = all_labels[test_fold_number*fold_n : fold_n+test_fold_number*fold_n]\n",
        "print(train_data.shape,test_data.shape) # (945, 32, 8064) (105, 32, 8064)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLBbybNs_cbS"
      },
      "outputs": [],
      "source": [
        "# -------- Feature extraction from 32 original signal --------\n",
        "train_band_power = [] # band power feature sequence for train trials\n",
        "for data in train_data: # for every train trial\n",
        "    with io.capture_output() as captured:\n",
        "        trial_band_power = trial_psd_extraction_integration(data) # data shape (32, 8064)\n",
        "    train_band_power.append(trial_band_power)\n",
        "train_band_power = np.array(train_band_power)\n",
        "\n",
        "test_band_power = [] # band power feature sequence for test trials\n",
        "for data in test_data: # for every test trial\n",
        "    with io.capture_output() as captured:\n",
        "        trial_band_power = trial_psd_extraction_integration(data) # data shape (32, 8064)\n",
        "    test_band_power.append(trial_band_power)\n",
        "test_band_power = np.array(test_band_power)\n",
        "print(\"All features of training data shape: \", train_band_power.shape) # shape (849, 125, 128)\n",
        "print(\"All features of test data shape: \", test_band_power.shape) # shape (95, 125, 128)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U58Dve0f_cbT"
      },
      "outputs": [],
      "source": [
        "# -------- Create new LSTM model --------\n",
        "x=Input(shape=(n_segment,bottleneck*4)) # flatten (12,4) to 48\n",
        "x1=LSTM(n_segment)(x)\n",
        "x2=Dense(n_segment)(x1)\n",
        "x3=Dense(12)(x2)\n",
        "output=Dense(1, activation=\"sigmoid\")(x2)\n",
        "model=Model(x, output)\n",
        "\n",
        "# -------- Compile and train LSTM --------\n",
        "model.compile(optimizer='SGD', loss='mse', metrics=['accuracy'])\n",
        "model.fit(train_band_power, train_labels, epochs=30, batch_size=8, validation_data=(test_band_power, test_labels))\n",
        "model.save(\"../Results/LSTM_model/LSTM_model_test_fold_\" + str(test_fold_number))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}